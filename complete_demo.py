#!/usr/bin/env python3
"""
å®Œæ•´çš„AIæ¥å£è‡ªåŠ¨åŒ–æµ‹è¯•æ¼”ç¤º
å±•ç¤ºï¼šé¡¹ç›®åˆ›å»º -> æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ -> æµ‹è¯•æ‰§è¡Œ -> æŠ¥å‘Šç”Ÿæˆ
"""
import asyncio
import json
import time
from datetime import datetime
from typing import Dict, Any, List

from src.agents.test_generator import TestCaseGeneratorAgent
from src.models.schemas import TestStatus, TestType, HTTPMethod, Priority

def print_header(title: str):
    """æ‰“å°æ ‡é¢˜"""
    print(f"\n{'='*60}")
    print(f"ğŸ¯ {title}")
    print(f"{'='*60}")

def print_step(step: str):
    """æ‰“å°æ­¥éª¤"""
    print(f"\nğŸ“‹ {step}")
    print("-" * 50)

async def simulate_test_execution(test_cases: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """æ¨¡æ‹Ÿæµ‹è¯•æ‰§è¡Œ"""
    results = []
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"   æ‰§è¡Œæµ‹è¯• {i}/{len(test_cases)}: {test_case['name']}")
        
        # æ¨¡æ‹Ÿç½‘ç»œè¯·æ±‚å»¶è¿Ÿ
        await asyncio.sleep(0.5)
        
        # æ¨¡æ‹Ÿä¸åŒçš„æµ‹è¯•ç»“æœ
        if "é”™è¯¯å¤„ç†" in test_case['name']:
            status = TestStatus.PASSED
            actual_status = 400
            response_time = 0.15
        elif "å®‰å…¨" in test_case['name']:
            status = TestStatus.FAILED
            actual_status = 200
            response_time = 0.25
            error_msg = "æ£€æµ‹åˆ°æ½œåœ¨çš„å®‰å…¨æ¼æ´"
        else:
            status = TestStatus.PASSED
            actual_status = test_case.get('expected_status', 200)
            response_time = 0.12
        
        result = {
            "test_case_id": i,
            "test_case_name": test_case['name'],
            "status": status,
            "response_time": response_time,
            "actual_status": actual_status,
            "expected_status": test_case.get('expected_status', 200),
            "actual_response": {"message": "success", "data": {}},
            "error_message": error_msg if status == TestStatus.FAILED else None,
            "started_at": datetime.now(),
            "completed_at": datetime.now()
        }
        results.append(result)
        
        # æ˜¾ç¤ºç»“æœ
        status_icon = "âœ…" if status == TestStatus.PASSED else "âŒ"
        print(f"      {status_icon} {status.value} ({response_time*1000:.0f}ms)")
    
    return results

def generate_test_report(results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    total_tests = len(results)
    passed_tests = len([r for r in results if r['status'] == TestStatus.PASSED])
    failed_tests = len([r for r in results if r['status'] == TestStatus.FAILED])
    
    avg_response_time = sum(r['response_time'] for r in results) / total_tests if total_tests > 0 else 0
    
    report = {
        "execution_summary": {
            "total_tests": total_tests,
            "passed": passed_tests,
            "failed": failed_tests,
            "pass_rate": f"{(passed_tests/total_tests*100):.1f}%" if total_tests > 0 else "0%",
            "avg_response_time": f"{avg_response_time*1000:.0f}ms"
        },
        "detailed_results": results,
        "ai_analysis": {
            "summary": "æµ‹è¯•æ‰§è¡Œå®Œæˆï¼Œå‘ç°1ä¸ªå®‰å…¨ç›¸å…³é—®é¢˜éœ€è¦å…³æ³¨",
            "insights": [
                "APIå“åº”æ—¶é—´æ•´ä½“è¡¨ç°è‰¯å¥½ï¼Œå¹³å‡å“åº”æ—¶é—´åœ¨å¯æ¥å—èŒƒå›´å†…",
                "åŠŸèƒ½æ€§æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼ŒåŸºç¡€åŠŸèƒ½è¿è¡Œæ­£å¸¸",
                "å®‰å…¨æµ‹è¯•å‘ç°æ½œåœ¨æ¼æ´ï¼Œå»ºè®®åŠ å¼ºè¾“å…¥éªŒè¯"
            ],
            "recommendations": [
                "å¯¹ç”¨æˆ·è¾“å…¥è¿›è¡Œæ›´ä¸¥æ ¼çš„éªŒè¯å’Œè¿‡æ»¤",
                "æ·»åŠ æ›´å¤šçš„è¾¹ç•Œå€¼æµ‹è¯•ç”¨ä¾‹",
                "è€ƒè™‘æ·»åŠ æ€§èƒ½å‹åŠ›æµ‹è¯•",
                "å»ºè®®å®æ–½APIè®¿é—®é¢‘ç‡é™åˆ¶"
            ],
            "risk_assessment": {
                "security_risk": "ä¸­ç­‰",
                "performance_risk": "ä½",
                "reliability_risk": "ä½"
            }
        },
        "generated_at": datetime.now().isoformat()
    }
    
    return report

async def main():
    """ä¸»æ¼”ç¤ºæµç¨‹"""
    print_header("AIæ¥å£è‡ªåŠ¨åŒ–æµ‹è¯•å®Œæ•´æ¼”ç¤º")
    
    # 1. é¡¹ç›®ä¿¡æ¯
    print_step("æ­¥éª¤1: é¡¹ç›®åˆå§‹åŒ–")
    project_info = {
        "name": "ç”µå•†APIå®Œæ•´æµ‹è¯•",
        "description": "æ¼”ç¤ºå®Œæ•´çš„AIè‡ªåŠ¨åŒ–æµ‹è¯•æµç¨‹",
        "base_url": "https://api.ecommerce-demo.com"
    }
    print(f"   é¡¹ç›®åç§°: {project_info['name']}")
    print(f"   é¡¹ç›®æè¿°: {project_info['description']}")
    print(f"   åŸºç¡€URL: {project_info['base_url']}")
    
    # 2. APIè§„èŒƒ
    api_spec = {
        "openapi": "3.0.0",
        "info": {
            "title": "ç”µå•†API",
            "version": "1.0.0",
            "description": "å®Œæ•´çš„ç”µå•†ç³»ç»ŸAPI"
        },
        "paths": {
            "/products": {
                "get": {
                    "summary": "è·å–å•†å“åˆ—è¡¨",
                    "parameters": [
                        {"name": "page", "in": "query", "schema": {"type": "integer"}},
                        {"name": "limit", "in": "query", "schema": {"type": "integer"}}
                    ],
                    "responses": {
                        "200": {"description": "æˆåŠŸè¿”å›å•†å“åˆ—è¡¨"},
                        "400": {"description": "è¯·æ±‚å‚æ•°é”™è¯¯"}
                    }
                },
                "post": {
                    "summary": "åˆ›å»ºæ–°å•†å“",
                    "requestBody": {
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "required": ["name", "price"],
                                    "properties": {
                                        "name": {"type": "string", "minLength": 1},
                                        "price": {"type": "number", "minimum": 0},
                                        "description": {"type": "string"}
                                    }
                                }
                            }
                        }
                    },
                    "responses": {
                        "201": {"description": "å•†å“åˆ›å»ºæˆåŠŸ"},
                        "400": {"description": "è¯·æ±‚æ•°æ®æ— æ•ˆ"}
                    }
                }
            },
            "/users/{id}": {
                "get": {
                    "summary": "è·å–ç”¨æˆ·ä¿¡æ¯",
                    "parameters": [
                        {"name": "id", "in": "path", "required": True, "schema": {"type": "integer"}}
                    ],
                    "responses": {
                        "200": {"description": "æˆåŠŸè¿”å›ç”¨æˆ·ä¿¡æ¯"},
                        "404": {"description": "ç”¨æˆ·ä¸å­˜åœ¨"}
                    }
                }
            },
            "/auth/login": {
                "post": {
                    "summary": "ç”¨æˆ·ç™»å½•",
                    "requestBody": {
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "required": ["username", "password"],
                                    "properties": {
                                        "username": {"type": "string"},
                                        "password": {"type": "string"}
                                    }
                                }
                            }
                        }
                    },
                    "responses": {
                        "200": {"description": "ç™»å½•æˆåŠŸ"},
                        "401": {"description": "è®¤è¯å¤±è´¥"}
                    }
                }
            }
        }
    }
    
    print(f"   APIç«¯ç‚¹æ•°é‡: {len(api_spec['paths'])}")
    print(f"   APIç‰ˆæœ¬: {api_spec['info']['version']}")
    
    # 3. AIæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ
    print_step("æ­¥éª¤2: AIæ™ºèƒ½ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹")
    print("   ğŸ¤– åˆå§‹åŒ–AIæµ‹è¯•ç”Ÿæˆæ™ºèƒ½ä½“...")
    
    generator = TestCaseGeneratorAgent("openai")
    
    generation_input = {
        "project_id": 1,
        "api_spec": api_spec,
        "test_types": [TestType.FUNCTIONAL, TestType.SECURITY],
        "max_cases_per_endpoint": 2
    }
    
    print("   âš¡ å¼€å§‹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹...")
    result = await generator.process(generation_input)
    
    if result["success"]:
        test_cases = result["test_cases"]
        print(f"   âœ… æˆåŠŸç”Ÿæˆ {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
        
        print("\n   ğŸ“ ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹:")
        for i, case in enumerate(test_cases, 1):
            print(f"      {i}. {case['name']}")
            print(f"         æ–¹æ³•: {case['method']} {case['endpoint']}")
            print(f"         ç±»å‹: {case['test_type']} | ä¼˜å…ˆçº§: {case['priority']}")
            print(f"         æè¿°: {case['description']}")
    else:
        print(f"   âŒ ç”Ÿæˆå¤±è´¥: {result['error']}")
        return
    
    # 4. æµ‹è¯•æ‰§è¡Œ
    print_step("æ­¥éª¤3: è‡ªåŠ¨åŒ–æµ‹è¯•æ‰§è¡Œ")
    print("   ğŸš€ å¼€å§‹æ‰§è¡Œæµ‹è¯•ç”¨ä¾‹...")
    
    execution_results = await simulate_test_execution(test_cases)
    
    print(f"\n   ğŸ“Š æ‰§è¡Œå®Œæˆï¼Œå…±æ‰§è¡Œ {len(execution_results)} ä¸ªæµ‹è¯•")
    
    # 5. æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ
    print_step("æ­¥éª¤4: AIæ™ºèƒ½åˆ†æä¸æŠ¥å‘Šç”Ÿæˆ")
    print("   ğŸ“ˆ ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")
    
    report = generate_test_report(execution_results)
    
    print(f"\n   ğŸ“‹ æµ‹è¯•æ‰§è¡Œæ‘˜è¦:")
    summary = report["execution_summary"]
    print(f"      æ€»æµ‹è¯•æ•°: {summary['total_tests']}")
    print(f"      é€šè¿‡: {summary['passed']} | å¤±è´¥: {summary['failed']}")
    print(f"      é€šè¿‡ç‡: {summary['pass_rate']}")
    print(f"      å¹³å‡å“åº”æ—¶é—´: {summary['avg_response_time']}")
    
    print(f"\n   ğŸ¤– AIåˆ†æç»“æœ:")
    analysis = report["ai_analysis"]
    print(f"      æ‘˜è¦: {analysis['summary']}")
    
    print(f"\n   ğŸ’¡ å…³é”®æ´å¯Ÿ:")
    for insight in analysis["insights"]:
        print(f"      â€¢ {insight}")
    
    print(f"\n   ğŸ”§ æ”¹è¿›å»ºè®®:")
    for recommendation in analysis["recommendations"]:
        print(f"      â€¢ {recommendation}")
    
    print(f"\n   âš ï¸  é£é™©è¯„ä¼°:")
    risks = analysis["risk_assessment"]
    print(f"      å®‰å…¨é£é™©: {risks['security_risk']}")
    print(f"      æ€§èƒ½é£é™©: {risks['performance_risk']}")
    print(f"      å¯é æ€§é£é™©: {risks['reliability_risk']}")
    
    # 6. ä¿å­˜æŠ¥å‘Š
    print_step("æ­¥éª¤5: ä¿å­˜æµ‹è¯•æŠ¥å‘Š")
    report_file = f"test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"   ğŸ’¾ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    # æ€»ç»“
    print_header("æ¼”ç¤ºå®Œæˆæ€»ç»“")
    print("ğŸ‰ AIæ¥å£è‡ªåŠ¨åŒ–æµ‹è¯•å®Œæ•´æµç¨‹æ¼”ç¤ºæˆåŠŸï¼")
    print("\nâœ¨ å±•ç¤ºçš„æ ¸å¿ƒåŠŸèƒ½:")
    print("   1. âœ… é¡¹ç›®ç®¡ç† - æ”¯æŒAPIè§„èŒƒå¯¼å…¥")
    print("   2. âœ… AIæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ - åŸºäºAPIè§„èŒƒæ™ºèƒ½ç”Ÿæˆ")
    print("   3. âœ… è‡ªåŠ¨åŒ–æµ‹è¯•æ‰§è¡Œ - å¹¶å‘æ‰§è¡Œï¼Œå®æ—¶ç›‘æ§")
    print("   4. âœ… AIæ™ºèƒ½åˆ†æ - æ·±åº¦åˆ†ææµ‹è¯•ç»“æœ")
    print("   5. âœ… æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ - è¯¦ç»†æŠ¥å‘Šï¼Œæ”¯æŒå¤šç§æ ¼å¼")
    
    print("\nğŸš€ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å»ºè®®:")
    print("   â€¢ é…ç½®çœŸå®çš„AIæ¨¡å‹APIå¯†é’¥")
    print("   â€¢ é›†æˆæ•°æ®åº“å­˜å‚¨æµ‹è¯•æ•°æ®")
    print("   â€¢ æ·»åŠ CI/CDé›†æˆ")
    print("   â€¢ é…ç½®å‘Šè­¦å’Œé€šçŸ¥æœºåˆ¶")
    print("   â€¢ æ‰©å±•æ›´å¤šæµ‹è¯•ç±»å‹ï¼ˆæ€§èƒ½ã€è´Ÿè½½ç­‰ï¼‰")
    
    print(f"\nğŸ“Š æœ¬æ¬¡æ¼”ç¤ºç»Ÿè®¡:")
    print(f"   â€¢ ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹: {len(test_cases)} ä¸ª")
    print(f"   â€¢ æ‰§è¡Œæµ‹è¯•: {len(execution_results)} ä¸ª")
    print(f"   â€¢ é€šè¿‡ç‡: {summary['pass_rate']}")
    print(f"   â€¢ æŠ¥å‘Šæ–‡ä»¶: {report_file}")

if __name__ == "__main__":
    asyncio.run(main())
