#!/usr/bin/env python3
"""
æ™ºèƒ½ä½“æ¡†æ¶å¯¹æ¯”æµ‹è¯•
åˆ†åˆ«æµ‹è¯•DeepSeekã€LangChainã€AutoGençš„æ•ˆæœ
"""
import asyncio
import json
import time
from datetime import datetime
from typing import Dict, Any

from src.agents.test_generator import TestCaseGeneratorAgent
from src.agents.autogen_agent import AutoGenMultiAgent
from src.agents.langchain_agent import LangChainTestAgent
from src.utils.logger import log


def print_banner():
    """æ‰“å°æ¨ªå¹…"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ”¬ æ™ºèƒ½ä½“æ¡†æ¶å¯¹æ¯”æµ‹è¯•                                      â•‘
â•‘                DeepSeek vs LangChain vs AutoGen                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)


def print_section(title: str, emoji: str = "ğŸ¯"):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print(f"\n{emoji} {title}")
    print("=" * 80)


def print_step(step: str, emoji: str = "ğŸ“‹"):
    """æ‰“å°æ­¥éª¤"""
    print(f"\n{emoji} {step}")
    print("-" * 60)


async def test_deepseek_framework():
    """æµ‹è¯•DeepSeekåŸºç¡€æ¡†æ¶"""
    print_section("DeepSeekåŸºç¡€æ™ºèƒ½ä½“æµ‹è¯•", "ğŸ§ ")
    
    print_step("åˆå§‹åŒ–DeepSeekæ™ºèƒ½ä½“")
    agent = TestCaseGeneratorAgent("ollama")
    print("   âœ… DeepSeek-R1:14b æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")
    print("   ğŸ¯ ç‰¹æ€§: æ€è€ƒæ¨ç†ã€ä¸­æ–‡ä¼˜åŒ–ã€æœ¬åœ°éƒ¨ç½²")
    
    # æµ‹è¯•APIè§„èŒƒ
    api_spec = {
        "openapi": "3.0.0",
        "info": {"title": "ç”µå•†API", "version": "1.0.0"},
        "paths": {
            "/products": {
                "get": {
                    "summary": "è·å–å•†å“åˆ—è¡¨",
                    "parameters": [
                        {"name": "category", "in": "query", "schema": {"type": "string"}},
                        {"name": "limit", "in": "query", "schema": {"type": "integer"}}
                    ],
                    "responses": {"200": {"description": "æˆåŠŸ"}}
                },
                "post": {
                    "summary": "åˆ›å»ºå•†å“",
                    "requestBody": {
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "name": {"type": "string"},
                                        "price": {"type": "number"},
                                        "category": {"type": "string"}
                                    },
                                    "required": ["name", "price"]
                                }
                            }
                        }
                    },
                    "responses": {"201": {"description": "åˆ›å»ºæˆåŠŸ"}}
                }
            },
            "/orders": {
                "post": {
                    "summary": "åˆ›å»ºè®¢å•",
                    "security": [{"bearerAuth": []}],
                    "responses": {"201": {"description": "è®¢å•åˆ›å»ºæˆåŠŸ"}}
                }
            }
        }
    }
    
    print_step("DeepSeekç”Ÿæˆæµ‹è¯•ç”¨ä¾‹")
    start_time = time.time()
    
    try:
        result = await agent.process({
            "project_id": 1,
            "api_spec": api_spec,
            "test_types": ["functional", "security"],
            "max_cases_per_endpoint": 3
        })
        
        end_time = time.time()
        duration = end_time - start_time
        
        print(f"   â±ï¸  ç”Ÿæˆè€—æ—¶: {duration:.2f} ç§’")
        print(f"   ğŸ“Š ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹: {len(result.get('test_cases', []))} ä¸ª")
        print(f"   âœ… ç”ŸæˆæˆåŠŸ: {result.get('success', False)}")
        
        # åˆ†ææµ‹è¯•ç”¨ä¾‹è´¨é‡
        test_cases = result.get('test_cases', [])
        if test_cases:
            print_step("DeepSeekæµ‹è¯•ç”¨ä¾‹è´¨é‡åˆ†æ")
            analyze_test_cases(test_cases, "DeepSeek")
        
        return {
            "framework": "DeepSeek",
            "success": result.get('success', False),
            "test_cases_count": len(test_cases),
            "duration": duration,
            "test_cases": test_cases,
            "ai_response_length": len(result.get('ai_response', '')),
            "features": ["æ€è€ƒæ¨ç†", "ä¸­æ–‡ä¼˜åŒ–", "æœ¬åœ°éƒ¨ç½²", "å¿«é€Ÿå“åº”"]
        }
        
    except Exception as e:
        print(f"   âŒ DeepSeekæµ‹è¯•å¤±è´¥: {e}")
        return {
            "framework": "DeepSeek",
            "success": False,
            "error": str(e),
            "test_cases_count": 0,
            "duration": 0
        }


async def test_langchain_framework():
    """æµ‹è¯•LangChainæ¡†æ¶"""
    print_section("LangChainå·¥å…·é“¾æ™ºèƒ½ä½“æµ‹è¯•", "ğŸ”—")
    
    print_step("åˆå§‹åŒ–LangChainæ™ºèƒ½ä½“")
    agent = LangChainTestAgent("ollama")
    print("   âœ… LangChainå·¥å…·é“¾æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")
    print("   ğŸ”§ å·¥å…·: api_analyzer, security_scanner, performance_analyzer, test_case_generator")
    print("   ğŸ¯ ç‰¹æ€§: å·¥å…·é“¾é›†æˆã€æ¨¡å—åŒ–åˆ†æã€å¯æ‰©å±•æ¶æ„")
    
    # ä½¿ç”¨ç›¸åŒçš„APIè§„èŒƒè¿›è¡Œå¯¹æ¯”
    api_spec = {
        "openapi": "3.0.0",
        "info": {"title": "ç”µå•†API", "version": "1.0.0"},
        "paths": {
            "/products": {
                "get": {
                    "summary": "è·å–å•†å“åˆ—è¡¨",
                    "parameters": [
                        {"name": "category", "in": "query", "schema": {"type": "string"}},
                        {"name": "limit", "in": "query", "schema": {"type": "integer"}}
                    ],
                    "responses": {"200": {"description": "æˆåŠŸ"}}
                },
                "post": {
                    "summary": "åˆ›å»ºå•†å“",
                    "requestBody": {
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "name": {"type": "string"},
                                        "price": {"type": "number"},
                                        "category": {"type": "string"}
                                    },
                                    "required": ["name", "price"]
                                }
                            }
                        }
                    },
                    "responses": {"201": {"description": "åˆ›å»ºæˆåŠŸ"}}
                }
            },
            "/orders": {
                "post": {
                    "summary": "åˆ›å»ºè®¢å•",
                    "security": [{"bearerAuth": []}],
                    "responses": {"201": {"description": "è®¢å•åˆ›å»ºæˆåŠŸ"}}
                }
            }
        }
    }
    
    print_step("LangChainå·¥å…·é“¾åˆ†æ")
    start_time = time.time()
    
    try:
        result = await agent.process({
            "project_id": 1,
            "api_spec": api_spec,
            "test_types": ["functional", "security"],
            "max_cases_per_endpoint": 3
        })
        
        end_time = time.time()
        duration = end_time - start_time
        
        print(f"   â±ï¸  åˆ†æè€—æ—¶: {duration:.2f} ç§’")
        print(f"   ğŸ“Š ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹: {len(result.get('test_cases', []))} ä¸ª")
        print(f"   ğŸ”§ ä½¿ç”¨å·¥å…·: {', '.join(result.get('tools_used', []))}")
        print(f"   âœ… åˆ†ææˆåŠŸ: {result.get('success', False)}")
        
        # åˆ†ææµ‹è¯•ç”¨ä¾‹è´¨é‡
        test_cases = result.get('test_cases', [])
        if test_cases:
            print_step("LangChainæµ‹è¯•ç”¨ä¾‹è´¨é‡åˆ†æ")
            analyze_test_cases(test_cases, "LangChain")
        
        return {
            "framework": "LangChain",
            "success": result.get('success', False),
            "test_cases_count": len(test_cases),
            "duration": duration,
            "test_cases": test_cases,
            "tools_used": result.get('tools_used', []),
            "features": ["å·¥å…·é“¾é›†æˆ", "æ¨¡å—åŒ–åˆ†æ", "å¯æ‰©å±•æ¶æ„", "ä¸“ä¸šå·¥å…·"]
        }
        
    except Exception as e:
        print(f"   âŒ LangChainæµ‹è¯•å¤±è´¥: {e}")
        return {
            "framework": "LangChain",
            "success": False,
            "error": str(e),
            "test_cases_count": 0,
            "duration": 0
        }


async def test_autogen_framework():
    """æµ‹è¯•AutoGenæ¡†æ¶"""
    print_section("AutoGenå¤šæ™ºèƒ½ä½“åä½œæµ‹è¯•", "ğŸ‘¥")
    
    print_step("åˆå§‹åŒ–AutoGenå¤šæ™ºèƒ½ä½“")
    agent = AutoGenMultiAgent("ollama")
    print("   âœ… AutoGenå¤šæ™ºèƒ½ä½“ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    print("   ğŸ‘¨â€ğŸ’¼ TestArchitect: æµ‹è¯•æ¶æ„å¸ˆ")
    print("   ğŸ”§ FunctionalTester: åŠŸèƒ½æµ‹è¯•ä¸“å®¶")
    print("   ğŸ”’ SecurityTester: å®‰å…¨æµ‹è¯•ä¸“å®¶")
    print("   âš¡ PerformanceTester: æ€§èƒ½æµ‹è¯•ä¸“å®¶")
    print("   ğŸ¯ ç‰¹æ€§: å¤šæ™ºèƒ½ä½“åä½œã€ä¸“ä¸šåˆ†å·¥ã€ç¾¤ä½“æ™ºèƒ½")
    
    # ä½¿ç”¨ç›¸åŒçš„APIè§„èŒƒè¿›è¡Œå¯¹æ¯”
    api_spec = {
        "openapi": "3.0.0",
        "info": {"title": "ç”µå•†API", "version": "1.0.0"},
        "paths": {
            "/products": {
                "get": {
                    "summary": "è·å–å•†å“åˆ—è¡¨",
                    "parameters": [
                        {"name": "category", "in": "query", "schema": {"type": "string"}},
                        {"name": "limit", "in": "query", "schema": {"type": "integer"}}
                    ],
                    "responses": {"200": {"description": "æˆåŠŸ"}}
                },
                "post": {
                    "summary": "åˆ›å»ºå•†å“",
                    "requestBody": {
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "name": {"type": "string"},
                                        "price": {"type": "number"},
                                        "category": {"type": "string"}
                                    },
                                    "required": ["name", "price"]
                                }
                            }
                        }
                    },
                    "responses": {"201": {"description": "åˆ›å»ºæˆåŠŸ"}}
                }
            },
            "/orders": {
                "post": {
                    "summary": "åˆ›å»ºè®¢å•",
                    "security": [{"bearerAuth": []}],
                    "responses": {"201": {"description": "è®¢å•åˆ›å»ºæˆåŠŸ"}}
                }
            }
        }
    }
    
    print_step("AutoGenå¤šæ™ºèƒ½ä½“åä½œ")
    start_time = time.time()
    
    try:
        result = await agent.process({
            "project_id": 1,
            "api_spec": api_spec,
            "test_types": ["functional", "security"],
            "max_cases_per_endpoint": 3
        })
        
        end_time = time.time()
        duration = end_time - start_time
        
        print(f"   â±ï¸  åä½œè€—æ—¶: {duration:.2f} ç§’")
        print(f"   ğŸ“Š ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹: {len(result.get('test_cases', []))} ä¸ª")
        print(f"   ğŸ‘¥ å‚ä¸æ™ºèƒ½ä½“: {', '.join(result.get('agents_involved', []))}")
        print(f"   âœ… åä½œæˆåŠŸ: {result.get('success', False)}")
        
        # åˆ†ææµ‹è¯•ç”¨ä¾‹è´¨é‡
        test_cases = result.get('test_cases', [])
        if test_cases:
            print_step("AutoGenæµ‹è¯•ç”¨ä¾‹è´¨é‡åˆ†æ")
            analyze_test_cases(test_cases, "AutoGen")
        
        return {
            "framework": "AutoGen",
            "success": result.get('success', False),
            "test_cases_count": len(test_cases),
            "duration": duration,
            "test_cases": test_cases,
            "agents_involved": result.get('agents_involved', []),
            "features": ["å¤šæ™ºèƒ½ä½“åä½œ", "ä¸“ä¸šåˆ†å·¥", "ç¾¤ä½“æ™ºèƒ½", "ååŒå†³ç­–"]
        }
        
    except Exception as e:
        print(f"   âŒ AutoGenæµ‹è¯•å¤±è´¥: {e}")
        return {
            "framework": "AutoGen",
            "success": False,
            "error": str(e),
            "test_cases_count": 0,
            "duration": 0
        }


def analyze_test_cases(test_cases: list, framework_name: str):
    """åˆ†ææµ‹è¯•ç”¨ä¾‹è´¨é‡"""
    if not test_cases:
        print("   âŒ æ— æµ‹è¯•ç”¨ä¾‹å¯åˆ†æ")
        return
    
    # ç»Ÿè®¡åˆ†æ
    methods = {}
    test_types = {}
    priorities = {}
    endpoints = set()
    
    for case in test_cases:
        # HTTPæ–¹æ³•ç»Ÿè®¡
        method = case.get('method', 'GET')
        methods[method] = methods.get(method, 0) + 1
        
        # æµ‹è¯•ç±»å‹ç»Ÿè®¡
        test_type = case.get('test_type', 'functional')
        test_types[test_type] = test_types.get(test_type, 0) + 1
        
        # ä¼˜å…ˆçº§ç»Ÿè®¡
        priority = case.get('priority', 'medium')
        priorities[priority] = priorities.get(priority, 0) + 1
        
        # ç«¯ç‚¹ç»Ÿè®¡
        endpoint = case.get('endpoint', '/')
        endpoints.add(endpoint)
    
    print(f"   ğŸ“Š æµ‹è¯•ç”¨ä¾‹æ€»æ•°: {len(test_cases)}")
    print(f"   ğŸ¯ è¦†ç›–ç«¯ç‚¹: {len(endpoints)} ä¸ª")
    print(f"   ğŸ”§ HTTPæ–¹æ³•åˆ†å¸ƒ: {dict(methods)}")
    print(f"   ğŸ“‹ æµ‹è¯•ç±»å‹åˆ†å¸ƒ: {dict(test_types)}")
    print(f"   â­ ä¼˜å…ˆçº§åˆ†å¸ƒ: {dict(priorities)}")
    
    # è´¨é‡è¯„åˆ†
    quality_score = calculate_quality_score(test_cases)
    print(f"   ğŸ† è´¨é‡è¯„åˆ†: {quality_score:.1f}/10.0")
    
    # æ˜¾ç¤ºå‰3ä¸ªæµ‹è¯•ç”¨ä¾‹ç¤ºä¾‹
    print(f"   ğŸ“ æµ‹è¯•ç”¨ä¾‹ç¤ºä¾‹:")
    for i, case in enumerate(test_cases[:3], 1):
        name = case.get('name', 'æœªå‘½å')[:40]
        method = case.get('method', 'GET')
        endpoint = case.get('endpoint', '/')
        print(f"      {i}. {name} - {method} {endpoint}")


def calculate_quality_score(test_cases: list) -> float:
    """è®¡ç®—æµ‹è¯•ç”¨ä¾‹è´¨é‡è¯„åˆ†"""
    if not test_cases:
        return 0.0
    
    score = 0.0
    total_points = 10.0
    
    # 1. æ•°é‡è¯„åˆ† (2åˆ†)
    count_score = min(len(test_cases) / 10.0 * 2, 2.0)
    score += count_score
    
    # 2. å¤šæ ·æ€§è¯„åˆ† (2åˆ†)
    methods = set(case.get('method', 'GET') for case in test_cases)
    diversity_score = min(len(methods) / 4.0 * 2, 2.0)
    score += diversity_score
    
    # 3. å®Œæ•´æ€§è¯„åˆ† (2åˆ†)
    complete_cases = sum(1 for case in test_cases 
                        if case.get('name') and case.get('endpoint') and case.get('expected_status'))
    completeness_score = complete_cases / len(test_cases) * 2
    score += completeness_score
    
    # 4. å®‰å…¨æ€§æµ‹è¯•è¯„åˆ† (2åˆ†)
    security_cases = sum(1 for case in test_cases if case.get('test_type') == 'security')
    security_score = min(security_cases / len(test_cases) * 4, 2.0)
    score += security_score
    
    # 5. æè¿°è´¨é‡è¯„åˆ† (2åˆ†)
    described_cases = sum(1 for case in test_cases 
                         if case.get('description') and len(case.get('description', '')) > 10)
    description_score = described_cases / len(test_cases) * 2
    score += description_score
    
    return min(score, total_points)


def compare_frameworks(results: list):
    """å¯¹æ¯”æ¡†æ¶ç»“æœ"""
    print_section("æ¡†æ¶å¯¹æ¯”åˆ†æ", "âš–ï¸")
    
    successful_frameworks = [r for r in results if r.get('success', False)]
    
    if not successful_frameworks:
        print("âŒ æ‰€æœ‰æ¡†æ¶æµ‹è¯•éƒ½å¤±è´¥äº†")
        return
    
    print_step("æˆåŠŸç‡ç»Ÿè®¡")
    print(f"   æ€»æµ‹è¯•æ¡†æ¶: {len(results)}")
    print(f"   æˆåŠŸæ¡†æ¶: {len(successful_frameworks)}")
    print(f"   æˆåŠŸç‡: {len(successful_frameworks)/len(results)*100:.1f}%")
    
    print_step("æ€§èƒ½å¯¹æ¯”")
    for result in successful_frameworks:
        framework = result['framework']
        duration = result.get('duration', 0)
        test_count = result.get('test_cases_count', 0)
        print(f"   ğŸš€ {framework}: {duration:.2f}ç§’, {test_count}ä¸ªæµ‹è¯•ç”¨ä¾‹")
    
    print_step("ç‰¹æ€§å¯¹æ¯”")
    for result in successful_frameworks:
        framework = result['framework']
        features = result.get('features', [])
        print(f"   ğŸ¯ {framework}: {', '.join(features)}")
    
    print_step("è´¨é‡å¯¹æ¯”")
    for result in successful_frameworks:
        framework = result['framework']
        test_cases = result.get('test_cases', [])
        if test_cases:
            quality_score = calculate_quality_score(test_cases)
            print(f"   ğŸ† {framework}: è´¨é‡è¯„åˆ† {quality_score:.1f}/10.0")
    
    # æ¨èæœ€ä½³æ¡†æ¶
    print_step("æ¡†æ¶æ¨è")
    if len(successful_frameworks) == 1:
        best_framework = successful_frameworks[0]['framework']
        print(f"   ğŸ¯ æ¨èä½¿ç”¨: {best_framework}")
    else:
        # ç»¼åˆè¯„åˆ†
        best_score = 0
        best_framework = None
        
        for result in successful_frameworks:
            framework = result['framework']
            test_cases = result.get('test_cases', [])
            quality_score = calculate_quality_score(test_cases) if test_cases else 0
            speed_score = max(0, 10 - result.get('duration', 10))  # é€Ÿåº¦è¯„åˆ†
            count_score = min(result.get('test_cases_count', 0) / 5, 10)  # æ•°é‡è¯„åˆ†
            
            total_score = quality_score + speed_score * 0.3 + count_score * 0.2
            
            print(f"   ğŸ“Š {framework}: ç»¼åˆè¯„åˆ† {total_score:.1f}")
            
            if total_score > best_score:
                best_score = total_score
                best_framework = framework
        
        if best_framework:
            print(f"   ğŸ† æœ€ä½³æ¡†æ¶: {best_framework} (è¯„åˆ†: {best_score:.1f})")


async def save_comparison_results(results: list):
    """ä¿å­˜å¯¹æ¯”ç»“æœ"""
    print_step("ä¿å­˜å¯¹æ¯”ç»“æœ")
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    comparison_data = {
        "timestamp": timestamp,
        "test_type": "framework_comparison",
        "frameworks": ["DeepSeek", "LangChain", "AutoGen"],
        "model_used": "deepseek-r1:14b",
        "results": results,
        "summary": {
            "total_frameworks": len(results),
            "successful_frameworks": len([r for r in results if r.get('success', False)]),
            "total_test_cases": sum(r.get('test_cases_count', 0) for r in results),
            "average_duration": sum(r.get('duration', 0) for r in results) / len(results) if results else 0
        }
    }
    
    filename = f"framework_comparison_{timestamp}.json"
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(comparison_data, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"   âœ… å¯¹æ¯”ç»“æœå·²ä¿å­˜: {filename}")
    return filename


async def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print_banner()
    
    results = []
    
    # 1. æµ‹è¯•DeepSeekæ¡†æ¶
    deepseek_result = await test_deepseek_framework()
    results.append(deepseek_result)
    
    # 2. æµ‹è¯•LangChainæ¡†æ¶
    langchain_result = await test_langchain_framework()
    results.append(langchain_result)
    
    # 3. æµ‹è¯•AutoGenæ¡†æ¶
    autogen_result = await test_autogen_framework()
    results.append(autogen_result)
    
    # 4. å¯¹æ¯”åˆ†æ
    compare_frameworks(results)
    
    # 5. ä¿å­˜ç»“æœ
    filename = await save_comparison_results(results)
    
    # 6. æ€»ç»“
    print_section("æµ‹è¯•å®Œæˆæ€»ç»“", "ğŸ‰")
    print("âœ¨ æ™ºèƒ½ä½“æ¡†æ¶å¯¹æ¯”æµ‹è¯•å®Œæˆï¼")
    
    successful_count = len([r for r in results if r.get('success', False)])
    total_test_cases = sum(r.get('test_cases_count', 0) for r in results)
    
    print(f"\nğŸ“Š æµ‹è¯•ç»Ÿè®¡:")
    print(f"   â€¢ æµ‹è¯•æ¡†æ¶: {len(results)} ä¸ª")
    print(f"   â€¢ æˆåŠŸæ¡†æ¶: {successful_count} ä¸ª")
    print(f"   â€¢ æ€»æµ‹è¯•ç”¨ä¾‹: {total_test_cases} ä¸ª")
    print(f"   â€¢ ç»“æœæ–‡ä»¶: {filename}")
    
    print(f"\nğŸ¯ æ¡†æ¶ç‰¹ç‚¹:")
    print("   â€¢ DeepSeek: æ€è€ƒæ¨ç†å¼ºã€ä¸­æ–‡ä¼˜åŒ–ã€æœ¬åœ°éƒ¨ç½²")
    print("   â€¢ LangChain: å·¥å…·é“¾ä¸°å¯Œã€æ¨¡å—åŒ–ã€å¯æ‰©å±•")
    print("   â€¢ AutoGen: å¤šæ™ºèƒ½ä½“åä½œã€ä¸“ä¸šåˆ†å·¥ã€ç¾¤ä½“æ™ºèƒ½")
    
    print(f"\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("   â€¢ å¿«é€ŸåŸå‹: é€‰æ‹©DeepSeekåŸºç¡€æ¡†æ¶")
    print("   â€¢ å¤æ‚åˆ†æ: é€‰æ‹©LangChainå·¥å…·é“¾")
    print("   â€¢ å›¢é˜Ÿåä½œ: é€‰æ‹©AutoGenå¤šæ™ºèƒ½ä½“")


if __name__ == "__main__":
    asyncio.run(main())
